{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "izJLCjEmKE14",
    "outputId": "189ae366-3663-42a1-ab7e-08c1d0ef4434"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vX9CpB0ULJ13",
    "outputId": "3170e647-738a-4820-e53b-0e55b3f0651f"
   },
   "outputs": [],
   "source": [
    "%cd /gdrive/My Drive/ANNDL-H1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm -rf ~/.nv/\n",
    "%env LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wSCplENNL075",
    "outputId": "a8ef9184-ce58-45fa-a485-d75c54129d7a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#DO NOOOOT DELETE, (Serve a nicola per la sua GPU)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "    \n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "import visualkeras\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yx5smRu9LphO"
   },
   "outputs": [],
   "source": [
    "# Dataset folders \n",
    "dataset_dir = '../../data'\n",
    "training_dir = os.path.join(dataset_dir, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXZr8OdKMykg",
    "outputId": "bd215fc4-2368-4a6c-be5f-6933444c0a89"
   },
   "outputs": [],
   "source": [
    "#Load Data Form Folder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "seed = 42\n",
    "batch_size = 8\n",
    "train_data_gen = ImageDataGenerator()\n",
    "\n",
    "train_data = train_data_gen.flow_from_directory(directory=training_dir,\n",
    "                                               target_size=(96,96),\n",
    "                                               color_mode='rgb',\n",
    "                                               classes=None, # can be set to labels\n",
    "                                               class_mode='categorical',\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               seed=seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "id": "QbWS7hulQX8N",
    "outputId": "fede1ead-27c6-4715-9679-f911b9e19fec"
   },
   "outputs": [],
   "source": [
    "images, labels = next(train_data)\n",
    "#https://towardsdatascience.com/introduction-to-keras-part-one-data-loading-43b9c015e27c\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(8):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow((images[i]).astype(np.uint8))\n",
    "    index = [index for index, each_item in enumerate(labels[i]) if each_item]\n",
    "    plt.title(list(train_data.class_indices.keys())[index[0]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "id": "NoCMdg0ot1VL",
    "outputId": "84f9157b-0d03-4c36-c8f9-7cf68b986e52"
   },
   "outputs": [],
   "source": [
    "#Now Go through all the batches and add them to the dataset\n",
    "from tqdm import tqdm\n",
    "X = [] #Training\n",
    "Y = [] #Testing\n",
    "dataset_size = 3542\n",
    "for j in tqdm(range(0,int(dataset_size/batch_size))):\n",
    "  images,labels = next(train_data)\n",
    "  for i in range(images.shape[0]):\n",
    "    X.append(images[i])\n",
    "    Y.append(labels[i])\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERyNxNvOOzA8"
   },
   "outputs": [],
   "source": [
    "#Split Training and Testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=seed, test_size=int(0.1 * dataset_size),stratify = Y)\n",
    "\n",
    "# Normalize data\n",
    "X_train = X_train/255.\n",
    "X_test = X_test/255.\n",
    "\n",
    "#Split Training and Validation\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, random_state=seed, test_size=int(0.1 * dataset_size),stratify = Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j1_PTiLaKemQ"
   },
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnC6Assj1CQk",
    "outputId": "ddecef38-3a41-4093-f808-45aeb7da60dd"
   },
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape,X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQGFEF-o_JP3",
    "outputId": "0659f8a6-da00-4790-8464-ef676fa3e762"
   },
   "outputs": [],
   "source": [
    "Y_train.shape,Y_test.shape,Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8C5Yz0_f5lUy"
   },
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:] # 96*96*3\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ybNbrWyQ5tKI"
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    # Build the neural network layer by layer\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
    "\n",
    "    conv1 = tfkl.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(5, 5),\n",
    "        strides = (1, 1),\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
    "    )(input_layer)\n",
    "    pool1 = tfkl.MaxPooling2D(pool_size = (2, 2))(conv1)\n",
    "\n",
    "    conv2 = tfkl.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
    "    )(pool1)\n",
    "    pool2 = tfkl.MaxPooling2D(pool_size = (2, 2))(conv2)\n",
    "\n",
    "    conv3 = tfkl.Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=(3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
    "    )(pool2)\n",
    "    pool3 = tfkl.MaxPooling2D(pool_size = (2, 2))(conv3)\n",
    "\n",
    "    flattening_layer = tfkl.Flatten(name='Flatten')(pool3)\n",
    "    classifier_layer = tfkl.Dense(\n",
    "        units=128, \n",
    "        name='Classifier', \n",
    "        activation='relu',\n",
    "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
    "    )(flattening_layer)\n",
    "    classifier_layer = tfkl.Dropout(0.5, seed=seed)(classifier_layer)\n",
    "    output_layer = tfkl.Dense(\n",
    "        units=8, \n",
    "        activation='softmax', \n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
    "        name='Output'\n",
    "    )(classifier_layer)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 771
    },
    "id": "oAj0gknl9DBw",
    "outputId": "a7dc46c1-7bce-420c-a9a6-f82ff874b386"
   },
   "outputs": [],
   "source": [
    "model = build_model(input_shape)\n",
    "model.summary()\n",
    "visualkeras.layered_view(model, legend=True, spacing=20, scale_xy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AnqJyhtzAYyB",
    "outputId": "c512a63e-5ed6-4931-c87e-3d08a6365720"
   },
   "outputs": [],
   "source": [
    "X_val.shape,Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HSdF2oDU9te7",
    "outputId": "823f675b-70fd-4ac8-8c62-6dbdfd8fe69e"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    x = X_train,\n",
    "    y = Y_train,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = (X_val, Y_val)\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "caZ09xI_GzL7",
    "outputId": "46944ba9-1e5a-4b19-8ec8-1687ee3d88ca"
   },
   "outputs": [],
   "source": [
    "#model.save('model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "yDzIfdpHHDgC",
    "outputId": "46d6b78b-a27a-4126-f036-a8a80107d8db"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = keras.models.load_model('model1')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EPPRFvJmSXV3"
   },
   "outputs": [],
   "source": [
    "labels = {0:'Species1', 1:'Species2', 2:'Species3', 3:'Species4',4:'Species5', 5:'Species6', 6:'Species7', 7:'Species8'}\n",
    "#Submission Model for the challenge -> Path is the folder on the server where our script is\n",
    "class model:\n",
    "    def __init__(self, path):\n",
    "        self.model = tf.keras.models.load_model(os.path.join(path, 'model1'))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        # Insert your preprocessing here\n",
    "\n",
    "        out = self.model.predict(X)\n",
    "        out = np.argmax(out, axis=-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qbvLsvjAU7ig"
   },
   "outputs": [],
   "source": [
    "testing_index = 44\n",
    "image_to_test = X_test[[testing_index],:]\n",
    "#image_to_test = X_test[10,None,:]\n",
    "#image_to_test = np.expand_dims(image_to_test,0)\n",
    "image_to_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Real Class: \")\n",
    "print(labels[np.argmax(Y_test[testing_index])])\n",
    "tester = model(\"\")\n",
    "res = tester.predict(image_to_test)\n",
    "labels[res[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_vector = model.predict(X_test)\n",
    "predicted_vector.shape\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_index = 98\n",
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "fig.set_size_inches(15,5)\n",
    "ax1.imshow(X_test[prediction_index])\n",
    "#Each class has its own score\n",
    "#We select the label with the largest prediction score \n",
    "ax1.set_title('True label: '+labels[np.argmax(Y_test[prediction_index])+1])\n",
    "ax2.barh(list(labels.values()), predicted_vector[prediction_index], color=plt.get_cmap('Paired').colors)\n",
    "ax2.set_title('Predicted label: '+labels[np.argmax(predicted_vector[prediction_index])])\n",
    "ax2.grid(alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
