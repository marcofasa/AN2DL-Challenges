{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "import visualkeras\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "print(tf.__version__)\n",
    "#ALLOW AUTORELOADING MODULES WHEN MODIFIED (Eg: our utility class)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../../Utils/')\n",
    "from DatasetHelper import DatasetHelper\n",
    "from ModelHelper import ModelHelper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Configuration:\n",
    "Configure\n",
    " the helper classes by setting a seed and the root folder path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Instances Of Utils Helper\n",
    "seed = 42\n",
    "labels = {0:'Species1', 1:'Species2', 2:'Species3', 3:'Species4',4:'Species5', 5:'Species6', 6:'Species7', 7:'Species8'}\n",
    "\n",
    "#Dataset Helper\n",
    "dataset_helper = DatasetHelper(\"../../\",42) #Take in input dataset folder and random seed\n",
    "\n",
    "#Model Helper\n",
    "#SAVE MODEL IN LOCAL, IF MODEL IS GOOD; COPY IT BY HAND TO good_model Folder\n",
    "model_helper   = ModelHelper(\"../../\",labels) #take in input local models folder and lables\n",
    "model_helper.create_seed(tf,seed);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loading and Preprocessing\n",
    "\n",
    "Load dataset and apply all the preprocessing operations\n",
    "- Splitting\n",
    "- Normalization\n",
    "- Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset\n",
    "X,Y = dataset_helper.load_dataset_from_numpy()\n",
    "#X,Y = dataset_helper.load_Dataset(22)\n",
    "\n",
    "dataset_size = X.shape[0]\n",
    "print(\"Dataset Size\" + str(dataset_size))\n",
    "\n",
    "#SPLIT and NORMALIZE OUR DATASET\n",
    "X_train,X_test,X_val,Y_train,Y_test,Y_val = dataset_helper.split_and_normalize(X,Y,split_test=0.1,split_val=0.2,normalization_mode = 1)\n",
    "\n",
    "X_train = X_train*255\n",
    "#GENERATE 3000 new images\n",
    "X_train,Y_train = dataset_helper.apply_data_augmentation(X_train,Y_train,6000)\n",
    "X_train = X_train/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 5000\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "columns = 10\n",
    "rows = 10\n",
    "for i in range(1, columns*rows +1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow((X[start+i]).astype(np.uint8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model Structure\n",
    "Create a function that declare all the model components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Model\n",
    "def build_model(input_shape):\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    # Build the neural network layer by layer\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
    "\n",
    "    conv1 = tfkl.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(5, 5),\n",
    "        strides = (1, 1),\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
    "    )(input_layer)\n",
    "    pool1 = tfkl.MaxPooling2D(pool_size = (2, 2))(conv1)\n",
    "\n",
    "    conv2 = tfkl.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
    "    )(pool1)\n",
    "    pool2 = tfkl.MaxPooling2D(pool_size = (2, 2))(conv2)\n",
    "\n",
    "    conv3 = tfkl.Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=(3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
    "    )(pool2)\n",
    "    pool3 = tfkl.MaxPooling2D(pool_size = (2, 2))(conv3)\n",
    "\n",
    "    flattening_layer = tfkl.Flatten(name='Flatten')(pool3)\n",
    "    classifier_layer = tfkl.Dense(\n",
    "        units=128, \n",
    "        name='Classifier', \n",
    "        activation='relu',\n",
    "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
    "    )(flattening_layer)\n",
    "    classifier_layer = tfkl.Dropout(0.5, seed=seed)(classifier_layer)\n",
    "    output_layer = tfkl.Dense(\n",
    "        units=8, \n",
    "        activation='softmax', \n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
    "        name='Output'\n",
    "    )(classifier_layer)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Phase\n",
    "Compile the model, configure all necessary infomation for training like epoch,batches, callbacks...\n",
    "Then start the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model\n",
    "input_shape = X_train.shape[1:]#(None,96,96,3)\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "\n",
    "model = build_model(input_shape)\n",
    "model.summary()\n",
    "visualkeras.layered_view(model, legend=True, spacing=20, scale_xy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "#Create ALL desired callbacks\n",
    "callbacks_selected = model_helper.createCallbacks(earlyStopping = True,checkPoints=True)\n",
    "\n",
    "#Fit the model\n",
    "history = model.fit(\n",
    "    x = X_train,\n",
    "    y = Y_train,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = (X_val, Y_val),\n",
    "    callbacks = callbacks_selected\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
